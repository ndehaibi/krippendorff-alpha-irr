{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Nomenclature\n",
    "# B beginning of review\n",
    "# L length of review (by characters)\n",
    "# b beginning of unit (how many characters in does the highlight begin)\n",
    "# l length of unit (by characters)\n",
    "# categories assigned by c or k\n",
    "# annotators identified by i or j\n",
    "# sections identified by g or h (for annotators i and j respectively)\n",
    "# gap or section defined by v (0 or 1 respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases that have not been highlighted must have empty cells in Excel (not have 0s).\n",
    "# Same applies to any \"Category\" cells corresponding to that phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def krippendorff_alpha_u(xlsx_file_url, sheet_name):\n",
    "    dictionary = store_annotation_data_in_dictionary(xlsx_file_url, sheet_name)\n",
    "    DocDec = calculate_obsereved_and_expected_disagreement(dictionary[0], dictionary[1], dictionary[2])\n",
    "    alphas = calculate_alpha(DocDec[0], DocDec[1])\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text))\n",
    "\n",
    "def store_annotation_data_in_dictionary(xlsx_file_url, sheet_name):\n",
    "    #### read data into data frame\n",
    "    import pandas as pd\n",
    "    df = pd.read_excel(xlsx_file_url, sheet_name=sheet_name)\n",
    "    # lowercase reviews\n",
    "    df['Review'] = df['Review'].str.lower()\n",
    "    # remove whitespace\n",
    "    df['Review'] = df['Review'].str.strip()\n",
    "    # remove numbers\n",
    "    df['Review'] = df['Review'].str.replace('\\d+', '')\n",
    "    # remove punctuation from reviews\n",
    "    df['Review'] = df['Review'].str.replace('[^\\w\\s]','')\n",
    "    # remove stop words\n",
    "    df['Review'] = df['Review'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
    "    # lemmatize reviews\n",
    "    df['Review'] =  df['Review'].apply(lemmatize_text)\n",
    "    # stem reviews\n",
    "    df['Review'] = df['Review'].apply(lambda x : filter(None,x.split(\" \")))\n",
    "    df['Review'] = df['Review'].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "    df['Review'] = df['Review'].apply(lambda x : \" \".join(x))\n",
    "    \n",
    "    B = 0\n",
    "    \n",
    "    # determine maximum number of highlights per review\n",
    "    n_highlights_max = 0\n",
    "    for col in df.columns:\n",
    "        if 'Phrase' in col:\n",
    "            n_highlights_max += 1\n",
    "\n",
    "    # determine maximum number of categories       \n",
    "    n_categories = 0\n",
    "    for i in range(1, n_highlights_max + 1):\n",
    "        # lowercase phrases\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].str.lower()\n",
    "        # remove whitespace\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].str.strip()\n",
    "        # remove numbers\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].str.replace('\\d+', '')\n",
    "        # remove punctuation from phrases\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].str.replace('[^\\w\\s]','')        \n",
    "        # remove stop words\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
    "        # lemmatize phrases\n",
    "        df['Phrase' + str(i)] =  df['Phrase' + str(i)].apply(lemmatize_text)        \n",
    "        # stem phrases\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].apply(lambda x : filter(None, str(x).split(\" \")))\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "        df['Phrase' + str(i)] = df['Phrase' + str(i)].apply(lambda x : \" \".join(x))\n",
    "        \n",
    "        if df['Category' + str(i)].isnull().all():\n",
    "            continue\n",
    "        n_category = int(df['Category' + str(i)].max())\n",
    "        if n_category > n_categories:\n",
    "            n_categories = n_category\n",
    "    n_categories += 1\n",
    "    print('number_of_categories: ' + str(n_categories))\n",
    "\n",
    "    annotation_data = [None]*n_categories\n",
    "    L_dict = {}\n",
    "\n",
    "    # populate dictionary with data from Excel file\n",
    "    for category in range(0, n_categories):\n",
    "        annotation_data[category] = {}\n",
    "        n_coder = 0\n",
    "        for index, row in df.iterrows():\n",
    "            #skip row if does not contain annotation\n",
    "            if row['Phrase1'] == '0' or row['Phrase1'] == 0 or row['Phrase1'] == '':\n",
    "                continue\n",
    "\n",
    "            # add review to dictionary\n",
    "            if 'review' + str(row.ID) in annotation_data[category].keys():\n",
    "                n_coder += 1\n",
    "            else:\n",
    "                n_coder = 0 \n",
    "                annotation_data[category]['review' + str(row.ID)] = {}\n",
    "            annotations = []\n",
    "            \n",
    "            # determine number of annotations\n",
    "            for i in range(1,n_highlights_max + 1):\n",
    "                #remove space at the end of a phrase if present\n",
    "                if str(row['Phrase'+str(i)]).endswith(' '):\n",
    "                    row['Phrase'+str(i)] = str(row['Phrase'+str(i)])[:-1]\n",
    "                #standardize 0 format \n",
    "                elif row['Phrase'+str(i)] == '0' or row['Phrase'+str(i)] == '0.0' or row['Phrase'+str(i)] == 0.0:\n",
    "                    row['Phrase'+str(i)] = 0  \n",
    "\n",
    "                if row['Category' + str(i)] == category:\n",
    "                    annotations.append(row['Phrase'+str(i)])\n",
    "                else:\n",
    "                    annotations.append(0)\n",
    "\n",
    "            n_highlights = n_highlights_max - annotations.count(0)\n",
    "            #n_sections = 2*(n_highlights)+1\n",
    "\n",
    "#             last_highlight_index = [index for index, item in enumerate(annotations) if item != 0]\n",
    "#             if len(last_highlight_index) != 0:\n",
    "#                 last_highlight_index = last_highlight_index[-1]\n",
    "\n",
    "            review = row.Review\n",
    "            L = len(review)\n",
    "            L_dict['review' + str(row.ID)] = L\n",
    "            b = [B]\n",
    "            l = []\n",
    "            \n",
    "            # make b vector\n",
    "            for i in range(1, n_highlights_max + 1):\n",
    "                if row['Category' + str(i)] == category:\n",
    "                    b += [review.find(str(row['Phrase'+str(i)])), review.find(str(row['Phrase'+str(i)])) + len(str(row['Phrase'+str(i)]))]\n",
    "\n",
    "            # make l vector\n",
    "            for i in range(len(b) - 1) : \n",
    "                l.append(abs(b[i] - b[i + 1]))\n",
    "            l.append(L - b[-1])\n",
    "\n",
    "            # make v vector\n",
    "            v = ([0, 1] * n_highlights) + [0]\n",
    "\n",
    "            if b == [B]:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            #adjust if there are multiple adjacent highlights for the same category\n",
    "            for j in range (0, l.count(1)):\n",
    "                if len(b) <= 3:\n",
    "                    continue           \n",
    "                for i in range(0, len(l)):\n",
    "\n",
    "                    if i >= len(l)-2:\n",
    "                        break\n",
    "                    if l[i] == 1:\n",
    "                        del b[i+1]\n",
    "                        del b[i]\n",
    "                        l[i-1] = l[i-1] + l[i+1] + l[i]\n",
    "                        del l[i+1]\n",
    "                        del l[i]\n",
    "                        del v[i+2]\n",
    "                        del v[i+1]\n",
    "\n",
    "\n",
    "            #store data properties in dictionary\n",
    "            annotation_data[category]['review' + str(row.ID)]['coder'+str(n_coder)]={}\n",
    "            annotation_data[category]['review' + str(row.ID)]['coder'+str(n_coder)]['b'] = b\n",
    "            annotation_data[category]['review' + str(row.ID)]['coder'+str(n_coder)]['l'] = l\n",
    "            annotation_data[category]['review' + str(row.ID)]['coder'+str(n_coder)]['v'] = v\n",
    "\n",
    "\n",
    "    print('annotation_data: ' + str(annotation_data))\n",
    "    print('length_of_reviews: ' + str(L_dict))\n",
    "    \n",
    "    return annotation_data, n_categories, L_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make doc and dec into dictionary\n",
    "def calculate_obsereved_and_expected_disagreement(annotation_data, n_categories, L_dict):\n",
    "    Doc = {}\n",
    "    Dec = {}\n",
    "    for category in range(0, n_categories):\n",
    "\n",
    "        Doc['category' + str(category)] = {}\n",
    "        Dec['category' + str(category)] = {}\n",
    "        for review in annotation_data[category]:\n",
    "            L = L_dict[review]\n",
    "            b = []\n",
    "            l = []\n",
    "            v = []\n",
    "            d = []\n",
    "            for coder in annotation_data[category][review]:\n",
    "                i = 0\n",
    "                # extract annotation propoerties into lists\n",
    "                for annotation in annotation_data[category][review][coder]:\n",
    "\n",
    "                    if i == 0:\n",
    "                        b0 = annotation_data[category][review][coder][annotation]\n",
    "                        b += b0\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    if i == 1:\n",
    "                        l0 = annotation_data[category][review][coder][annotation]\n",
    "                        l += l0\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    if i == 2:\n",
    "                        v0 = annotation_data[category][review][coder][annotation]\n",
    "                        v += v0\n",
    "                        i = 0\n",
    "\n",
    "                        # loop through other annotations\n",
    "                        for other_coder in annotation_data[category][review]:\n",
    "                            for other_annotation in annotation_data[category][review][other_coder]:\n",
    "                                if i == 0:\n",
    "                                    b1 = annotation_data[category][review][other_coder][other_annotation]\n",
    "                                    i += 1\n",
    "                                    continue\n",
    "                                if i == 1:\n",
    "                                    l1 = annotation_data[category][review][other_coder][other_annotation]\n",
    "                                    i += 1\n",
    "                                    continue\n",
    "                                if i == 2:\n",
    "                                    v1 = annotation_data[category][review][other_coder][other_annotation]\n",
    "                                    i = 0\n",
    "\n",
    "                                    if b1 == b0 and l1 == l0 and v1 == v0:\n",
    "                                        d.append(0)\n",
    "                                        continue\n",
    "\n",
    "                                    # calculate difference d between two annotations\n",
    "                                    b0_limit = len(b0)-1\n",
    "                                    b1_limit = len(b1)-1\n",
    "                                    #d = []\n",
    "                                    vec = []\n",
    "                                    vec.append(b0)\n",
    "                                    vec.append(b1)\n",
    "\n",
    "                                    if len(b0)>len(b1):\n",
    "                                        for index, x in enumerate(b0):\n",
    "                                            if index >= b1_limit:\n",
    "                                                # if both are units\n",
    "                                                if v1[b1_limit] == 1 and v0[index] == 1:\n",
    "                                                    # if there is no overlap\n",
    "                                                    if (b0[index] + l0[index]) < b1[b1_limit] or b1[b1_limit] + l1[b1_limit]<b0[index]:\n",
    "                                                        d.append(l0[index]**2 + l1[b1_limit]**2)\n",
    "                                                    # if there is overlap\n",
    "                                                    if (b0[index] <= b1[b1_limit] + l1[b1_limit] <= b0[index] + l0[index]) or (b1[b1_limit] <= b0[index] + l0[index] <= b1[b1_limit] + l1[b1_limit]):\n",
    "                                                        d.append((b0[index]-b1[b1_limit])**2+(b0[index]+l0[index]-b1[b1_limit]-l1[b1_limit])**2)\n",
    "                                                elif v1[b1_limit] == 1 and v0[index] == 0:\n",
    "                                                    d.append(l1[b1_limit]**2)\n",
    "                                                elif v1[b1_limit] == 0 and v0[index] == 1:\n",
    "                                                    d.append(l0[index]**2)\n",
    "                                                else:\n",
    "                                                    d.append(0)\n",
    "                                            else:\n",
    "                                                # if both are units\n",
    "                                                if v1[index] == 1 and v0[index] == 1:\n",
    "                                                    # if there is no overlap\n",
    "                                                    if (b0[index] + l0[index]) < b1[index] or b1[index] + l1[index]<b0[index]:\n",
    "                                                        d.append(l0[index]**2 + l1[index]**2)\n",
    "                                                    # if there is overlap\n",
    "                                                    if (b0[index] <= b1[index] + l1[index] <= b0[index] + l0[index]) or (b1[index] <= b0[index] + l0[index] <= b1[index] + l1[index]):\n",
    "                                                        d.append((b0[index]-b1[index])**2+(b0[index]+l0[index]-b1[index]-l1[index])**2)\n",
    "                                                elif v1[index] == 1 and v0[index] == 0:\n",
    "                                                    d.append(l1[index]**2)\n",
    "                                                elif v1[index] == 0 and v0[index] == 1:\n",
    "                                                    d.append(l0[index]**2)\n",
    "                                                else:\n",
    "                                                    d.append(0)\n",
    "                                    else:\n",
    "                                        for index, x in enumerate(b1):\n",
    "                                            if index >= b0_limit:\n",
    "                                                # if both are units\n",
    "                                                if v1[index] == 1 and v0[b0_limit] == 1:\n",
    "                                                    # if there is no overlap\n",
    "                                                    if (b0[b0_limit] + l0[b0_limit]) < b1[index] or b1[index] + l1[index]<b0[b0_limit]:\n",
    "                                                        d.append(l0[b0_limit]**2 + l1[index]**2)\n",
    "                                                    # if there is overlap\n",
    "                                                    if (b0[b0_limit] <= b1[index] + l1[index] <= b0[b0_limit] + l0[b0_limit]) or (b1[index] <= b0[b0_limit] + l0[b0_limit] <= b1[index] + l1[index]):\n",
    "                                                        d.append((b0[b0_limit]-b1[index])**2+(b0[b0_limit]+l0[b0_limit]-b1[index]-l1[index])**2)\n",
    "                                                elif v1[index] == 1 and v0[b0_limit] == 0:\n",
    "                                                    d.append(l1[index]**2)\n",
    "                                                elif v1[index] == 0 and v0[b0_limit] == 1:\n",
    "                                                    d.append(l0[b0_limit]**2)\n",
    "                                                else:\n",
    "                                                    d.append(0)\n",
    "                                            else:\n",
    "                                                # if both are units\n",
    "                                                if v1[index] == 1 and v0[index] == 1:\n",
    "                                                    # if there is no overlap\n",
    "                                                    if (b0[index] + l0[index]) < b1[index] or b1[index] + l1[index]  < b0[index]:\n",
    "                                                        d.append(l0[index]**2 + l1[index]**2)\n",
    "                                                    # if there is overlap\n",
    "                                                    if (b0[index] <= b1[index] + l1[index] <= b0[index] + l0[index]) or (b1[index] <= b0[index] + l0[index] <= b1[index] + l1[index]):\n",
    "                                                        d.append((b0[index]-b1[index])**2+(b0[index]+l0[index]-b1[index]-l1[index])**2)\n",
    "                                                elif v1[index] == 1 and v0[index] == 0:\n",
    "                                                    d.append(l1[index]**2)\n",
    "                                                elif v1[index] == 0 and v0[index] == 1:\n",
    "                                                    d.append(l0[index]**2)\n",
    "                                                else:\n",
    "                                                    d.append(0)\n",
    "\n",
    "\n",
    "\n",
    "            # append doc for each review\n",
    "            m = len(annotation_data[category][review])\n",
    "\n",
    "            if m == 1 or m == 0:\n",
    "                continue\n",
    "\n",
    "            Doc['category' + str(category)][review] = (sum(d)/(m*(m-1)*L**2))\n",
    "\n",
    "            # Calculate Dec\n",
    "            n=v.count(1)\n",
    "            numerator = 0\n",
    "            second_term_d=0\n",
    "            second_term_n = 0        \n",
    "            for index, x in enumerate(b):\n",
    "                if v[index] == 1:\n",
    "                    second_term_d += l[index]*(l[index]-1)\n",
    "                    first_term_n = ((n-1)/3)*((2*(l[index]**3))-(3*l[index]**2)+l[index])\n",
    "                    second_term_n = 0\n",
    "                    for index_1, x_1 in enumerate(b):\n",
    "                        if l[index_1] >= l[index] and v[index_1] ==0:\n",
    "                            second_term_n += (l[index_1]-l[index]+1)\n",
    "                    numerator += first_term_n + (l[index]**2)*second_term_n\n",
    "\n",
    "\n",
    "            numerator = (2/L)*numerator\n",
    "            first_term_d = m*L*(m*L-1)\n",
    "            denominator = first_term_d - second_term_d\n",
    "\n",
    "            # append dec for each review\n",
    "            Dec['category' + str(category)][review] = (numerator / denominator)\n",
    "\n",
    "    print('Doc_by_category: ' + str(Doc))\n",
    "    print('Dec_by_category: ' + str(Dec))\n",
    "    \n",
    "    return Doc, Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alpha(Doc, Dec):\n",
    "    import numpy as np\n",
    "    #### Alpha intercoder agreement\n",
    "    alpha_category = {}\n",
    "    alpha_combined = {}\n",
    "    ## alpha for each category\n",
    "    for category in Doc:\n",
    "        for review in Doc[category]:\n",
    "            if review in alpha_category.keys():\n",
    "                pass\n",
    "            else:\n",
    "                alpha_category[review] = {}\n",
    "            alpha_category[review][category] = 1 - (Doc[category][review]/Dec[category][review])\n",
    "    print('alpha_by_category: ' + str(alpha_category))\n",
    "\n",
    "    ## combined alpha\n",
    "    alpha_combined = {}\n",
    "    sum_Doc = {}\n",
    "    sum_Dec = {}\n",
    "\n",
    "    # calculate Doc and Dec sum\n",
    "    for category in Doc:\n",
    "        for review in Doc[category]:\n",
    "            if review in sum_Doc.keys():\n",
    "                pass\n",
    "            else:\n",
    "                sum_Doc[review] = 0\n",
    "                sum_Dec[review] = 0\n",
    "            sum_Doc[review] += Doc[category][review]\n",
    "            sum_Dec[review] += Dec[category][review]\n",
    "\n",
    "    # calculate alpha    \n",
    "    for review in sum_Doc:\n",
    "        if review in alpha_combined.keys():\n",
    "            pass\n",
    "        else:\n",
    "            alpha_combined[review] = {}\n",
    "        alpha_combined[review] = 1 - sum_Doc[review] / sum_Dec[review]\n",
    "    print('alpha_combined: ' + str(alpha_combined))\n",
    "    \n",
    "    return alpha_category, alpha_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sustainability = 'Economic' # Social, Envrionmental, or Economic\n",
    "output = krippendorff_alpha_u(\"/Users/ndehaibi/Desktop/Research/Study 2/IRR/IRR Test (\" + str(sustainability) + \").xlsx\", 'IRR')\n",
    "alpha_combined = list((output[1].values()))\n",
    "from matplotlib import pyplot as plt\n",
    "bins = 10\n",
    "arr = plt.hist(alpha_combined, bins)\n",
    "plt.ylabel('Review Count')\n",
    "plt.xlabel('Intercoder Agreement')\n",
    "plt.title(str(sustainability) + ' Sustainability - Letters with NLP')\n",
    "for i in range(bins):\n",
    "    plt.text(arr[1][i],arr[0][i] + 1.2,str(arr[0][i]))\n",
    "print(len(alpha_combined))\n",
    "import statistics\n",
    "print('mean: ' + str(statistics.mean(alpha_combined)))\n",
    "print('std dev: ' + str(statistics.stdev(alpha_combined)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
